{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn-mario-image-part1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RuaanV/datascience-notebook/blob/master/cnn_mario_image_part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "clg6yeul6KSn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Excercising CNN code base on the Medium article -  [Mario vs. Wario — round 2: CNNs in PyTorch and Google Colab](https://towardsdatascience.com/mario-vs-wario-round-2-cnns-in-pytorch-and-google-colab-48b968cf4ace)"
      ]
    },
    {
      "metadata": {
        "id": "mqSd6yN3vOvN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "4a66705b-f903-4b77-dd3f-72dcffc11b26"
      },
      "cell_type": "code",
      "source": [
        "# inspect the os \n",
        "!cat /etc/*-release"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DISTRIB_ID=Ubuntu\n",
            "DISTRIB_RELEASE=18.04\n",
            "DISTRIB_CODENAME=bionic\n",
            "DISTRIB_DESCRIPTION=\"Ubuntu 18.04.1 LTS\"\n",
            "NAME=\"Ubuntu\"\n",
            "VERSION=\"18.04.1 LTS (Bionic Beaver)\"\n",
            "ID=ubuntu\n",
            "ID_LIKE=debian\n",
            "PRETTY_NAME=\"Ubuntu 18.04.1 LTS\"\n",
            "VERSION_ID=\"18.04\"\n",
            "HOME_URL=\"https://www.ubuntu.com/\"\n",
            "SUPPORT_URL=\"https://help.ubuntu.com/\"\n",
            "BUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\n",
            "PRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\n",
            "VERSION_CODENAME=bionic\n",
            "UBUNTU_CODENAME=bionic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Dksdn5i-vd5d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "b51c58f1-10ca-40ab-a851-fcfc7bf23d6f"
      },
      "cell_type": "code",
      "source": [
        "# inspect GPU and RAM ----\n",
        "\n",
        "# memory footprint support libraries/code\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "\n",
        "import GPUtil as GPU\n",
        "import os\n",
        "import humanize\n",
        "import psutil\n",
        "!ln - sf / opt/bin/nvidia-smi / usr/bin/nvidia-smi\n",
        "\n",
        "GPUs = GPU.getGPUs()\n",
        "gpu = GPUs[0]\n",
        "\n",
        "\n",
        "def printm():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available),\n",
        "          \" | Proc size: \" + humanize.naturalsize(process.memory_info().rss))\n",
        "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(\n",
        "        gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "\n",
        "\n",
        "printm()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "ln: target 'usr/bin/nvidia-smi' is not a directory\n",
            "Gen RAM Free: 12.8 GB  | Proc size: 352.5 MB\n",
            "GPU RAM Free: 11441MB | Used: 0MB | Util   0% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vnYlQiE9IhIo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Install the libraries used in these code snippets"
      ]
    },
    {
      "metadata": {
        "id": "TaWnevr1IdIJ",
        "colab_type": "code",
        "outputId": "e268f0c4-6fc6-4247-d9e5-f984e15a66af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install pytube\n",
        "!pip3 install lime\n",
        "\n",
        "# Loading libraries ----\n",
        "\n",
        "# misc\n",
        "import os\n",
        "import shutil\n",
        "from random import sample, randint, shuffle\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from skimage.segmentation import mark_boundaries\n",
        "\n",
        "# sci-kit learn\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# plots\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "# youtube\n",
        "from pytube import YouTube\n",
        "\n",
        "# image operation\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "# keras \n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from keras.applications import inception_v3 as inc_net\n",
        "\n",
        "# lime\n",
        "import lime\n",
        "from lime import lime_image\n",
        "\n",
        "print('Notebook run using keras:', keras.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytube\n",
            "  Downloading https://files.pythonhosted.org/packages/e3/59/75fc847184855f701afa64d5604873032d7908ca8660a10d2e79cede4ddf/pytube-9.4.0-py3-none-any.whl\n",
            "Installing collected packages: pytube\n",
            "Successfully installed pytube-9.4.0\n",
            "Collecting lime\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/59/8342382ba3301ec02a9d1a30a6d9d9c19484344a9201c5c3d83295332d44/lime-0.1.1.32.tar.gz (266kB)\n",
            "\u001b[K    100% |████████████████████████████████| 276kB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lime) (1.14.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lime) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from lime) (0.20.2)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.6/dist-packages (from lime) (0.13.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (1.0.1)\n",
            "Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (2.2)\n",
            "Requirement already satisfied: matplotlib>=1.3.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (3.0.2)\n",
            "Requirement already satisfied: six>=1.7.3 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (1.11.0)\n",
            "Requirement already satisfied: pillow>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (4.0.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=1.8->scikit-image>=0.12->lime) (4.3.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.3.1->scikit-image>=0.12->lime) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.3.1->scikit-image>=0.12->lime) (2.5.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.3.1->scikit-image>=0.12->lime) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.3.1->scikit-image>=0.12->lime) (2.3.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=2.1.0->scikit-image>=0.12->lime) (0.46)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.3.1->scikit-image>=0.12->lime) (40.7.1)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/48/13/7c/20792e4efe5fd04237c0ac92bc8551acfe36392e09953ac8ea\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.1.1.32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Notebook run using keras: 2.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NJPQcHgLG-Eh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# UDFs ----\n",
        "\n",
        "def scrape_frames(video_name, dest_path, n_images, skip_seconds):\n",
        "    # function for scraping frames from videos\n",
        "    vidcap = cv2.VideoCapture(video_name)\n",
        "    total_frames = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    fps = int(vidcap.get(cv2.CAP_PROP_FPS))\n",
        "    every_x_frame = math.floor((total_frames - skip_seconds * fps) / n_images) - 1\n",
        "\n",
        "    success,image = vidcap.read()\n",
        "    frame_count = 0\n",
        "    img_count = 0\n",
        "    \n",
        "    while success: \n",
        "        success,image = vidcap.read() #success might be false and image might be None\n",
        "        \n",
        "        if frame_count > (skip_seconds * 30):\n",
        "            # break if the video ended\n",
        "            if not success:\n",
        "                break\n",
        "\n",
        "            # action on every x-th frame \n",
        "            if (frame_count % every_x_frame == 0):\n",
        "                cv2.imwrite(dest_path + \"_\" + str(img_count) + '.jpg', image)   \n",
        "                img_count += 1\n",
        "                if (round(img_count / n_images, 2) * 100 % 10 == 0): \n",
        "                    print(\"Completed:\", round(img_count / n_images, 2), \"done.\", end=\"\\r\")\n",
        "\n",
        "            if img_count == n_images:\n",
        "                break   \n",
        "            \n",
        "        frame_count += 1\n",
        "        \n",
        "def move_random_files(path_from, path_to, n):\n",
        "    # function for moving random files from one directory to another (used for creating train and test set)\n",
        "    files = os.listdir(path_from)\n",
        "    files.sort()\n",
        "    files = files[1:] #omiting .DS_Store\n",
        "\n",
        "    for i in sample(range(0, len(files)-1), n):\n",
        "        f = files[i]\n",
        "        src = path_from + f\n",
        "        dst = path_to + f\n",
        "        shutil.move(src, dst)\n",
        "        \n",
        "def preview_random_image(path):\n",
        "    # function for previewing a random image from a given directory\n",
        "    files = os.listdir(path)\n",
        "    files.sort()\n",
        "    img_name = files[randint(1, len(files) - 1)]\n",
        "    img_preview_name = path + img_name\n",
        "    image = Image.open(img_preview_name)\n",
        "    plt.imshow(image)\n",
        "    plt.title(img_name)\n",
        "    plt.show()\n",
        "    width, height = image.size\n",
        "    print (\"Dimensions:\", image.size, \"Total pixels:\", width * height)\n",
        "    \n",
        "def pretty_cm(y_pred, y_truth, labels):\n",
        "    # pretty implementation of a confusion matrix\n",
        "    cm = metrics.confusion_matrix(y_truth, y_pred)\n",
        "    ax= plt.subplot()\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", linewidths=.5, square = True, cmap = 'BuGn_r')\n",
        "    # labels, title and ticks\n",
        "    ax.set_xlabel('Predicted label')\n",
        "    ax.set_ylabel('Actual label')\n",
        "    ax.set_title('Accuracy: {0}'.format(metrics.accuracy_score(y_truth, y_pred)), size = 15) \n",
        "    ax.xaxis.set_ticklabels(labels)\n",
        "    ax.yaxis.set_ticklabels(labels)\n",
        "    \n",
        "def img_to_1d_greyscale(img_path, size):\n",
        "    # function for loading, resizing and converting an image into greyscale\n",
        "    # used for logistic regression\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.resize(img, size)\n",
        "    return(pd.Series(img.flatten()))\n",
        "\n",
        "def show_image(image):\n",
        "    # function for viewing an image\n",
        "    fig = plt.figure(figsize = (5, 25))\n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.imshow(image, interpolation='none')\n",
        "    plt.show()\n",
        "\n",
        "def transform_image(path, size):\n",
        "    # function for transforming images into a format supported by CNN\n",
        "    x = load_img(path, target_size=(size[0], size[1]))\n",
        "    x = img_to_array(x) / 255\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    return (x)\n",
        "\n",
        "def evaluation_indices(y_pred, y_test):\n",
        "    # function for getting correctly and incorrectly classified indices\n",
        "    index = 0\n",
        "    correctly_classified_indices = []\n",
        "    misclassified_indices = []\n",
        "    for label, predict in zip(y_test, y_pred):\n",
        "        if label != predict: \n",
        "            misclassified_indices.append(index)\n",
        "        else:\n",
        "            correctly_classified_indices.append(index)\n",
        "        index +=1\n",
        "    return (correctly_classified_indices, misclassified_indices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bt4wu62AG_EW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Downloading **YouTube** clip"
      ]
    },
    {
      "metadata": {
        "id": "5u359YxmGuKS",
        "colab_type": "code",
        "outputId": "67ece7dd-1cb3-4ea4-bf4d-1d55909f408d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "mario_video = YouTube('https://www.youtube.com/watch?v=lXMJt5PP3kM')\n",
        "\n",
        "# viewing available video formats \n",
        "print('Title:', mario_video.title, '---')\n",
        "stream = mario_video.streams.filter(file_extension = \"mp4\").all()\n",
        "for i in stream:\n",
        "    print(i)\n",
        "    \n",
        "# downloading the video\n",
        "mario_video.streams.get_by_itag(18).download(\"/content/gdrive/My Drive/\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Title: Game Boy Longplay [005] Super Mario Land 2: 6 Golden Coins ---\n",
            "<Stream: itag=\"18\" mime_type=\"video/mp4\" res=\"360p\" fps=\"30fps\" vcodec=\"avc1.42001E\" acodec=\"mp4a.40.2\">\n",
            "<Stream: itag=\"133\" mime_type=\"video/mp4\" res=\"240p\" fps=\"30fps\" vcodec=\"avc1.4d400b\">\n",
            "<Stream: itag=\"160\" mime_type=\"video/mp4\" res=\"144p\" fps=\"30fps\" vcodec=\"avc1.4d400b\">\n",
            "<Stream: itag=\"140\" mime_type=\"audio/mp4\" abr=\"128kbps\" acodec=\"mp4a.40.2\">\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/Game Boy Longplay [005] Super Mario Land 2 6 Golden Coins.mp4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "QuGTiejRv__V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "efb6e619-6133-4513-c170-35c04037dc19"
      },
      "cell_type": "code",
      "source": [
        "wario_video = YouTube('https://www.youtube.com/watch?v=ZJuxdR0KH-s')\n",
        "# viewing available video formats \n",
        "print('Title:', wario_video.title, '---')\n",
        "stream = wario_video.streams.filter(file_extension = \"mp4\").all()\n",
        "for i in stream:\n",
        "    print(i)\n",
        "    \n",
        "# downloading the video\n",
        "wario_video.streams.get_by_itag(18).download(\"/content/gdrive/My Drive/\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Title: Game Boy Longplay [004] Super Mario Land 3: Wario Land ---\n",
            "<Stream: itag=\"18\" mime_type=\"video/mp4\" res=\"360p\" fps=\"30fps\" vcodec=\"avc1.42001E\" acodec=\"mp4a.40.2\">\n",
            "<Stream: itag=\"133\" mime_type=\"video/mp4\" res=\"240p\" fps=\"30fps\" vcodec=\"avc1.4d400d\">\n",
            "<Stream: itag=\"160\" mime_type=\"video/mp4\" res=\"144p\" fps=\"30fps\" vcodec=\"avc1.4d400b\">\n",
            "<Stream: itag=\"140\" mime_type=\"audio/mp4\" abr=\"128kbps\" acodec=\"mp4a.40.2\">\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/Game Boy Longplay [004] Super Mario Land 3 Wario Land.mp4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "ZMutPwK6HW1b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Cut the frames from the video"
      ]
    },
    {
      "metadata": {
        "id": "-F4ZnToPwMdH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "175131a2-492c-412f-d8e7-507763c4dd03"
      },
      "cell_type": "code",
      "source": [
        "!ls '/content/'"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Game Boy Longplay [004] Super Mario Land 3 Wario Land.mp4'\t  gdrive\n",
            "'Game Boy Longplay [005] Super Mario Land 2 6 Golden Coins.mp4'   sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TT_GTqOxxEQ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "5bab92d8-64ee-4de7-ea02-0af9518f60e2"
      },
      "cell_type": "code",
      "source": [
        "# Cut the video frames\n",
        "\n",
        "# getting frames from Mario\n",
        "scrape_frames('Game Boy Longplay [005] Super Mario Land 2 6 Golden Coins.mp4', \n",
        "              \"/content/gdrive/My Drive/training_set/mario/\",\n",
        "               \n",
        "              n_images = 5000,\n",
        "              skip_seconds = 60)\n",
        "\n",
        "# removed parameter - every_x_frame = 50,"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-CBS7ZjuxZEQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "f7b6ffec-b287-4229-ac4c-47fbd98c9e5d"
      },
      "cell_type": "code",
      "source": [
        "# getting frames from Wario\n",
        "scrape_frames('Game Boy Longplay [004] Super Mario Land 3 Wario Land.mp4', \n",
        "              \"/content/gdrive/My Drive/training_set/wario/\",\n",
        "               \n",
        "              n_images = 5000,\n",
        "              skip_seconds = 60)\n",
        "\n",
        "# removed parameter - every_x_frame = 50,"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6q9wZ5Iq1tXK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing\n",
        "\n",
        "## Splitting data into training and test sets"
      ]
    },
    {
      "metadata": {
        "id": "aOlYcrxN9BOd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Mount Google drive to store images"
      ]
    },
    {
      "metadata": {
        "id": "-ynGx6NE8v6n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "d9579077-eb7b-40da-c09f-9028eafc9cb1"
      },
      "cell_type": "code",
      "source": [
        "# connect to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nhfDcPUVHVvU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "move_random_files(path_from = \"/content/gdrive/My Drive/training_set/mario/\", \n",
        "                  path_to = \"/content/gdrive/My Drive/test_set/mario/\", \n",
        "                  n = 1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PW_4iAiYHpQp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "move_random_files(path_from = \"/content/gdrive/My Drive/training_set/wario/\", \n",
        "                  path_to = \"/content/gdrive/My Drive/test_set/wario/\", \n",
        "                  n = 1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9emO0e956JVq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "buLRz6ny7rRR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hJU9wXEg9kOU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Fetch the images files and store them in my Google drive"
      ]
    },
    {
      "metadata": {
        "id": "9b0cENZx9H3Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "\n",
        "# create directory for storing data\n",
        "!mkdir -p data\n",
        "\n",
        "# download zip file with training set\n",
        "!gdown https://drive.google.com/uc?id=1z_vO2muBgzNGIa7JtY8OPmaeUC348jj4 && unzip -qq training_set.zip -d data/training_set\n",
        "!rm training_set.zip\n",
        "\n",
        "# download zip with test set\n",
        "!gdown https://drive.google.com/uc?id=1ziwxAVrbDRfUTYMrFu0sn1B8OH-6gvej && unzip -qq test_set.zip -d data/test_set\n",
        "!rm test_set.zip\n",
        "\n",
        "# remove some leftover dir\n",
        "!rm -r /content/data/test_set/__MACOSX/\n",
        "\n",
        "# change dir to the one with data \n",
        "!cd /content/data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gb5aIbKBAhAo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# change dir to the one with data \n",
        "!cd /content/data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aDTQ-H7yDRyJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 install torch torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WTMubmWx-LA6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Loading data"
      ]
    },
    {
      "metadata": {
        "id": "nTgdVfll9ivI",
        "colab_type": "code",
        "outputId": "a5190443-b811-4fe5-b648-67bb4ba9df92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "\n",
        "# 1. defining parameters ----\n",
        "\n",
        "# number of subprocesses to use for data loading\n",
        "num_workers = 0\n",
        "# number of samples to load per batch\n",
        "batch_size = 32\n",
        "# % of training set to use as validation\n",
        "valid_size = 0.2\n",
        "\n",
        "# define transformations that will be applied to images\n",
        "image_transforms = transforms.Compose([transforms.Resize((128, 128)),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# 2. define the datasets ----\n",
        "train_data = datasets.ImageFolder(root='data/training_set/', transform=image_transforms)\n",
        "test_data = datasets.ImageFolder(root='data/test_set/', transform=image_transforms)\n",
        "\n",
        "# 3. obtain indices that will be used for validation ----\n",
        "num_train = len(train_data)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(valid_size * num_train))\n",
        "train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "# define samplers for obtaining training and validation batches\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "# 4. prepare data loaders (combine dataset with sampler) ----\n",
        "train_loader = torch.utils.data.DataLoader(train_data,\n",
        "                                           batch_size = batch_size,\n",
        "                                           sampler = train_sampler, \n",
        "                                           num_workers = num_workers,\n",
        "                                           pin_memory = pin_memory)\n",
        "valid_loader = torch.utils.data.DataLoader(train_data,\n",
        "                                           batch_size = batch_size, \n",
        "                                           sampler = valid_sampler, \n",
        "                                           num_workers = num_workers,\n",
        "                                           pin_memory = pin_memory)\n",
        "test_loader = torch.utils.data.DataLoader(test_data,\n",
        "                                          shuffle = True,\n",
        "                                          batch_size = batch_size, \n",
        "                                          num_workers = num_workers,\n",
        "                                          pin_memory = pin_memory)\n",
        "\n",
        "# specify the image classes ----\n",
        "classes = ['mario', 'wario']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-f6def8867a58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# define samplers for obtaining training and validation batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mtrain_sampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSubsetRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mvalid_sampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSubsetRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SubsetRandomSampler' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "p2moJL0a-rcv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}